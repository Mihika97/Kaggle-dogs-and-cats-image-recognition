{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version - 2.0.0\n",
      "Keras Version - 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from random import shuffle\n",
    "from time import time\n",
    "# tensorboard --logdir=logs/ --host localhost --port 8088\n",
    "\n",
    "print(f'TensorFlow Version - {tf.__version__}')\n",
    "print(f'Keras Version - {tf.keras.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'train'\n",
    "TEST_DIR = 'test1'\n",
    "IMG_SIZE = 50\n",
    "LR = 0.0003\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "MODEL_NAME = 'dogs_cats_LR-{}_MODEL-{}.h5'.format(LR,'CovNet-128(2)-64(2)-32(2)-512-128-1')\n",
    "MODEL_PATH = os.path.join('saved_models',MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(saved=True):\n",
    "    \"\"\"This method returns the model used.\n",
    "    Returns a saved model if MODEL_NAME is found.\n",
    "    CovNet Architecture\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    saved - Get the saved model from the MODEL_PATH if exists.(default True)\n",
    "    \n",
    "    Returns:\n",
    "    model - The complete uncompiled Keras model.\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    tf.compat.v1.get_default_graph\n",
    "    a = tf.constant(1)\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "         tf.compat.v1.get_default_graph()\n",
    "       \n",
    "    \n",
    "    \n",
    "    if os.path.isfile(MODEL_PATH) and saved :\n",
    "        print(\"Loading saved model {}\".format(MODEL_NAME))\n",
    "        return load_model(MODEL_PATH)\n",
    "    \n",
    "    # Declaring model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Block\n",
    "    model.add(Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 1),filters=128, kernel_size=5, strides=1,padding='same',name = 'blk1_conv1'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=5, strides=1,padding='same',name = 'blk1_conv2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'blk1_mxPool'))\n",
    "\n",
    "    # 2nd Block\n",
    "    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'blk2_conv1'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'blk2_conv2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'blk2_mxPool'))\n",
    "    \n",
    "    # 3rd Block\n",
    "    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv1'))\n",
    "    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'blk3_mxPool'))\n",
    "\n",
    "    # 4th Block - FC Block\n",
    "    dr_rate = 0.35\n",
    "    model.add(Flatten(name = 'blk4_flatten'))\n",
    "    model.add(Dropout(dr_rate,name = 'blk4_droupout1'))\n",
    "    model.add(Dense(512, activation='relu',name = 'blk4_dense1'))\n",
    "    model.add(Dropout(dr_rate,name = 'blk4_droupout2'))\n",
    "    model.add(Dense(128, activation='relu',name = 'blk4_dense2'))\n",
    "    model.add(Dropout(dr_rate,name = 'blk4_droupout3'))\n",
    "    model.add(Dense(1, activation='sigmoid',name = 'blk4_dense3'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(img):\n",
    "    \"\"\"Returns the label for an image.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    img - The filename of the image whose label we want to get.\n",
    "    \n",
    "    Returns:\n",
    "    list object - The respective label for dog or cat. (dog = 1, cat = 0)\n",
    "    \"\"\"\n",
    "    word = img.split('.')[0]\n",
    "    if word == 'cat':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    \"\"\"Returns the training data from TRAIN_DIR.\n",
    "    Images are read in grayscale format and resized to IMG_SIZE dimension square.\n",
    "    The whole data is saved with numpy in .npy format for quick loading for future purpose.\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    if os.path.isfile('training_data_{}.npy'.format(IMG_SIZE)):\n",
    "         import numpy as np\n",
    "      \n",
    "\n",
    "         np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "         np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "\n",
    "         return np.load('training_data_{}.npy'.format(IMG_SIZE))\n",
    "    else:\n",
    "        for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "            label = get_label(img)\n",
    "            path = os.path.join(TRAIN_DIR,img)\n",
    "            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\n",
    "            img = img/255\n",
    "            training_data.append([np.array(img),np.array(label)])\n",
    "        shuffle(training_data)\n",
    "        np.save('training_data_{}.npy'.format(IMG_SIZE),training_data)\n",
    "        return np.array(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_data():\n",
    "    \"\"\"Returns the testing data from TEST_DIR.\n",
    "    Images are read in grayscale format and resized to IMG_SIZE dimension square.\n",
    "    The whole data is saved with numpy in .npy format for quick loading for future purpose.\n",
    "    \"\"\"\n",
    "    testing_data = []\n",
    "    if os.path.isfile('testing_data_{}.npy'.format(IMG_SIZE)):\n",
    "        return np.load('testing_data_{}.npy'.format(IMG_SIZE))\n",
    "    else:\n",
    "        for img in tqdm(os.listdir(TEST_DIR)):\n",
    "            img_id = int(img.split('.')[0])\n",
    "            path = os.path.join(TEST_DIR,img)\n",
    "            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\n",
    "            img = img/255\n",
    "            testing_data.append([np.array(img),img_id])\n",
    "        testing_data.sort(key = lambda x: x[1])\n",
    "        np.save('testing_data_{}.npy'.format(IMG_SIZE),testing_data)\n",
    "        return np.array(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_training_data()\n",
    "\n",
    "partition = 1000             # Breaking -ve index\n",
    "train = data[:-partition]    # For Training purpose\n",
    "test= data[-partition:]      # For Validation purpose\n",
    "\n",
    "# Training set\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "y_train = np.array([i[1] for i in train])\n",
    "\n",
    "# Validation set\n",
    "X_val = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "y_val = np.array([i[1] for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Effects added on image\n",
    "    Rotation - ± 50 deegrees,\n",
    "    Width Shift - ± 15 %\n",
    "    Height Shift - ± 15 %\n",
    "    Zoom - 30%\n",
    "    Horizontal Flip\n",
    "    Vertical Flip\n",
    "\"\"\"\n",
    "datagen = ImageDataGenerator(rotation_range=20,width_shift_range=0.05,height_shift_range=0.05,\n",
    "                            zoom_range=0.05,horizontal_flip=True,vertical_flip=False)\n",
    "\n",
    "# Calculation of necessary internal data for all images.\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "blk1_conv1 (Conv2D)          (None, 50, 50, 128)       3328      \n",
      "_________________________________________________________________\n",
      "blk1_conv2 (Conv2D)          (None, 50, 50, 128)       409728    \n",
      "_________________________________________________________________\n",
      "blk1_mxPool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "blk2_conv1 (Conv2D)          (None, 25, 25, 64)        204864    \n",
      "_________________________________________________________________\n",
      "blk2_conv2 (Conv2D)          (None, 25, 25, 64)        102464    \n",
      "_________________________________________________________________\n",
      "blk2_mxPool (MaxPooling2D)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "blk3_conv1 (Conv2D)          (None, 12, 12, 32)        51232     \n",
      "_________________________________________________________________\n",
      "blk3_conv2 (Conv2D)          (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "blk3_mxPool (MaxPooling2D)   (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "blk4_flatten (Flatten)       (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "blk4_droupout1 (Dropout)     (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "blk4_dense1 (Dense)          (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "blk4_droupout2 (Dropout)     (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "blk4_dense2 (Dense)          (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "blk4_droupout3 (Dropout)     (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "blk4_dense3 (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,453,377\n",
      "Trainable params: 1,453,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "# Optimizer (Adam Optimizer)\n",
    "adam = Adam(lr = LR)\n",
    "\n",
    "# Callbacks Declared\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()),batch_size=BATCH_SIZE)\n",
    "       #Supported in new version of keras ,update_freq='epoch')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.3,patience=3,verbose=1,\n",
    "                              mode='max', min_lr=0.000001)\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=3,verbose=1,mode='min')\n",
    "      #Supported in new version of keras ,restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(filepath=MODEL_PATH,monitor='val_acc',verbose=1,save_best_only=True,\n",
    "                                  mode='max',period=3)\n",
    "\n",
    "model.compile(optimizer = adam,loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduce_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a292fd5b02ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgenerator_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgenerator_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reduce_lr' is not defined"
     ]
    }
   ],
   "source": [
    "# Toggle if dont want to train using Image Augmentation\n",
    "from keras.callbacks import TensorBoard\n",
    "generator_train = True\n",
    "EPOCHS = 30\n",
    "callbacks=[TensorBoard,reduce_lr,early_stop,model_checkpoint]\n",
    "\n",
    "if generator_train:\n",
    "    print(f'Training model {MODEL_NAME} using Image Augmentation')\n",
    "    hist = model.fit_generator(datagen.flow(X_train,y_train,batch_size=BATCH_SIZE),\n",
    "                               steps_per_epoch=len(X_train)//BATCH_SIZE,epochs=EPOCHS,verbose=2,\n",
    "                               validation_data=(X_val,y_val),callbacks=callbacks)\n",
    "else:\n",
    "    print(f'Training model {MODEL_NAME} using normal image data provided')\n",
    "    hist = model.fit(X_train,y_train,epochs=EPOCHS,batch_size=BATCH_SIZE,validation_data=(X_val,y_val),\n",
    "                     verbose=2,callbacks=callbacks)\n",
    "#model.save(MODEL_PATH)     Redundant Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
